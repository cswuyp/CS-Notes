* [正则表达式](#正则表达式)
* [爬虫的基本原理](#爬虫的基本原理)
* [Scrapy框架入门简介](#scrpay框架入门简介)


# 正则表达式
https://www.liaoxuefeng.com/wiki/0014316089557264a6b348958f449949df42a6d3a2e542c000/00143193331387014ccd1040c814dee8b2164bb4f064cff000

# 爬虫的基本原理
爬虫是获取网页并提取和保存信息的自动化程序。  
### 1.获取网页
爬虫首先要做的工作是获取网页，这里就是获取网页的源码。源代码里包含了网页的部分有用信息，所以只要把源代码获取下来，就可以从中提取想要的信息。我们首先要想服务器发送一个请求，服务器返回的响应体就是网页源代码。所以，最关键的部分是构造一个请求并发送给服务器，然后接收到响应并将其解析出来。Python提供了许多库来帮助我们实现这个操作，如urllib、request等，我们可以用这些库来帮助我们实现HTTP请求操作，请求和响应都可以用类库提供的数据结构来表示，得到响应之后只需要解析数据结构中的Body部分即可，即得到网页的源代码，这样我们可以用程序来实现获取网页的过程了。  
### 2.提取信息
获取网页源代码之后，接下来就是分析网页源码，从中提取我们想要的数据。首先，最通用的 方法便是采用正则表达式提取，这是一个万能的方法， 但是在构造正则表达式时比较复杂且容易出错。另外由于网页的结构有一定的规则，所以还有一些根据网页节点属性、CSS选择器或XPath来提取网页信息的库，如pyquery、lxml等。使用这些库，我们可以高效快速地从中提取网页信息，如节点的属性、文本值等。  
### 3.保存数据
提取信息后，我们一般会将提取到的数据保存到某处以便后续使用。这里保存形式有多种多样，如可以简单的保存为TXT文本或JSON文本，也可以保存到数据库，如MySQL和MongoDB等
# scrapy框架入门简介
https://segmentfault.com/a/1190000013178839
