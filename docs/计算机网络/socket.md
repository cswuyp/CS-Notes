* [网络IO模型](#网络IO模型)
* [IO多路复用](#io多路复用)
  * [1.select系统调用](#1-select系统调用)
  * [2.poll系统调用](#2-poll系统调用)
  * [3.epoll系统调用](#3-epoll系统调用)  
  * [4.select、poll、epoll的区别](#4-select、poll、epoll的区别) 
* [I/O复用函数的比较](#io复用函数的比较)
# 网络IO模型
　　IO（Input/Output,输入/输出）是计算机体系中重要的一部分。IO类外设有打印机、键盘、复印机等；存储类型的设备则有硬盘、磁盘、U盘等；通信设备有网卡、路由器等。不同的IO设备有着不同的特点：数据率不一样、传送单位不一样、数据表示不一样，等等。所以，很难实现一种统一的输入/输出方法。
  
　　IO有两种操作，同步IO和异步IO。同步IO指的是，必须等待IO操作完成后，控制权才返回给用户进程。异步IO指的是，无须等待IO操作完成，就将控制权返回用户进程。  
  
　　网络中的IO，由于不同的IO设备有着不用的特点，网络通信中往往需要等待。常见的有以下四种情况。  
  （1）输入操作：等待数据到达套接字接收缓冲区。
  
  （2）输出操作：等待套接字发送缓冲区有足够的空间容纳将要发送的数据。
  
  （3）服务器接收连接请求：等待新的客户端连接请求的到来。
  
  （4）客户端发送连接请求：等待服务器回送客户的发起的SYN所对应的ACK。   　
   
　　当一个网络IO发生时，它会涉及两个系统对象，一个是调试这个IO的进程，另一个是系统内核。当一个read操作发生时，它会经历两个阶段：（1）等待数据准备；
  （2）将数据从内核拷贝到进程中。
  
4种网络IO模型：（1）阻塞IO模型（2）非阻塞IO模型（3）多路IO复用模型（4）异步IO模型
---
# IO多路复用
　　I/O复用使得程序能同时监听多个文件描述符，这对提高程序的性能至关重要。通常网络程序在下列情况下需要使用I/O复用技术：  
1.客户端程序要同时处理多个socket。  

2.客户端程序要同时处理用户输入和网络连接。  

3.TCP服务器要同时处理监听socket和连接socket。这是I/O复用使用最多的场合。  

4.服务器要同时处理TCP请求和UDP请求。  

5.服务器要同时监听多个端口，或者处理多种服务。  

　　只要指出的是，I/O复用虽然能同时监听多个文件描述符，但它本身是阻塞的。并且当多个文件描述符同时就绪时，如果不采取额外的措施，程序就只能按顺序依次处理其中的每一个文件描述符，这使得服务器看起来像是串行工作的。如果要实现并发，只能使用多进程或多线程等编程手段。
  
　　Linux下实现I/O复用的系统调用主要有select、poll和epoll。
  
  # 1. select系统调用
  select系统调用的用途是：在一段指定时间内，监听用户感兴趣的文件描述符上的可读、可写和异常等事件。
  https://www.cnblogs.com/wuyepeng/p/9740240.html  
  https://www.cnblogs.com/wuyepeng/p/9745573.html  
  https://www.cnblogs.com/wuyepeng/p/9726771.html  
  
  ## 文件描述符就绪条件
  哪些情况下文件描述符可以被认为是可读、可写、或者出现异常，对于select的使用非常关键。在网络编程中，下列情况下socket可读：  
  1.socket内核接收缓存区中的字节数大于或等于其低水平位标记SO_RCVLOWAT。此时我们可以无阻塞的地读该socket，并且读操作返回的字节数大于0.  
  2.socket通信的对方关闭连接。此时对该socket的读操作将返回0.  
  3.监听socket上有新的连接请求。  
  4.socket上有未处理的错误。此时我们可以使用getsockopt来读取和清除该错误。  
  下来情况下socket可写：  
  5.socket内核发送缓存区中的可用字节数大于或等于其低水平位标记SO_SNDLOWAT。此时我们可以无阻塞地写socket，并且写操作返回的字节数大于0.  
  6.socket的写操作被关闭，对写操作被关闭的socket执行写操作将触发一个SIGPIPE信号。  
  7.socket使用非阻塞connect连接成功或者失败（超时）之后。  
  8.socket上有未处理的错误。此时我们可以使用getsockopt来读取和清除该错误。  
  网络程序中，select能处理的异常情况只有一种：socket上接收到外数据。
  
  
  # 2. poll系统调用
  poll系统调用和select类似，也是在指定时间内轮询一定数量的文件描述符，以测试其中是否有就绪者。
  https://www.cnblogs.com/wuyepeng/p/9751087.html
  
  
  
  
  # 3. epoll系统调用
  epoll是Linux特有的I/O复用函数。它在实现和使用上与select、poll有很大差异。首先，epoll使用一组函数来完成任务，而不是单个函数。其次，epoll把用户关心的文件描述符上的事件放在内核里的一个事件表中，这样在用户空间和内核空间之间的数据拷贝只需一次。从而无需像select和poll那样每次调用都需重复传入文件描述符集和事件集。但epoll需要使用一个额外的文件描述符，来唯一标识内核中的这个事件表。这个文件描述符使用如下epoll_create函数来创建：
  ```c++
  #include<sys/epoll.h>
  int epoll_create(int size)
  ```
  https://www.cnblogs.com/wuyepeng/p/9727085.html
  
  # 4. select、poll、epoll的区别
  
　　select、poll和epoll都是多路IO复用的机制。多路IO复用就通过一种机制，可以监视多个描述符，一旦某个文件描述符就绪（一般是读就绪或者是写就绪），能够通知程序进行相应的读写操作。但select、poll和epoll本质上都是同步IO，因为它们都需要在读写事件就绪后自己负责进行读写，即是阻塞的，而异步IO则无须自己负责进行读写，异步I/O的实现会负责把数据从内核拷贝到用户空间。
  
  ### 下面对这3种多路IO复用进行对比。
  
 （1）首先还是来看常见的select()和poll()。对于网络编程来说，一般认为poll()比select高级一些，这主要源于以下几个原因。
 
 1）poll不要求开发者在计算最大文件描述符时进行+1的操作。  
 2）poll()在应付大数目的文件描述符的时候速度更快，因为对于select()来说内核需要检查大量描述符对应的fd_set中的每一个比特位，比较费时。  
 3）select()可以监视的文件描述符数目是固定的，相对来说也较少（1024或2048）。如果需要监控数值比较大的文件描述符，或是分布得很稀疏的较少的描述符，效率也会很低。而对于poll()函数来说，就可以创建特定大小的数组来保存监控的描述符，而不受文件描述符值大小的影响，而且poll()可以监控的文件描述符的文件数目远大于select()。  
 4）对于select()来说，所监控的fd_set()在select返回之后会发生变化，所以在下一次进入select()之前都需要重新初始化需要监控的fd_set，poll()函数将监控的输入和输出事件分开，允许被监控的文件数组被复用而不需要重新初始化。  
 5）select()函数的超时参数在返回时也是未定义的，考虑到可移植性，每次在超时之后在下一次进入到select()之前都需要重新设置超时参数。
 
 （2）select的优点如下所述。  
 
 1）select()可移植性更好，在某些UNIX系统上不支持poll()。  
 2）select()对于超时值提供了更好的精确度，而poll是精确度较差。  
 
 （3）epoll的优点如下所述。  
 
 1）支持一个进程打开大数目的socket描述符（FD）。
 　　select()最不能忍受的是一个进程所打开的FD是有一定限制的，由于FD_SETSIZE的默认值是1024/2048。对于那些需要支持上万连接数目的IM服务器来说显然太少了。这时候可以选择修改这个宏然后重新编译内核。不过epoll则没有这个限制，它所支持的FD上限是最大可以打开文件的数目，这个数字一般远大于2048.举一个例子，在1GB内存的空间中这个数字一般是10万左右，具体数目可以使用cat/proc/sys/fs/file-max查看，一般来说这个数目和系统内存关系很大。
   
 2）IO效率不随FD数目增加而线性下降。  
 　　传统的select/poll另一个致命弱点就是当你拥有一个很大的socket集合，不过由于网络延迟，任一时间只有部分的socket是“活跃”的，但是select/poll每次调用都会线性扫描全部的集合，导致效率呈现线性下降。但是epoll不存在这个问题，它只会对“活跃”的socket进行操作——这是因为在内核中实现epoll是根据每个fd上面的callback函数实现的。那么，只有“活跃”的socket才会主动去调用callback函数，其他idle状态socket则不会，在这点上，epoll实现了一个“伪”AIO，因为这时候推动力由Linux内核提供。
   
 3)使用mmap加速内核与用户空间的消息传递  
 　　这点实际上涉及epoll的具体实现。无论是select、poll还是epoll都需要内核把fd消息通知给用户空间，如何避免不必要的内存拷贝就显得尤为重要。在这点上，epoll是通过内核与用户空间mmap处于同一块内存实现的。  
 　　对于poll来说需要将用户传入的pollfd的数组拷贝到内核空间，因为拷贝操作和数组长度相关，时间上来看，这是一个O(n)操作，当事件发生后，poll将获得的数据传送到用户空间，并执行释放内存和剥离等待队列等工作，想用户空间拷贝数据与剥离等待队列等操作的时间复杂度同样是O(1).
   
 select、poll和epoll提供服务器的并发处理能力，以节约机器成本。
    
  # I/O复用函数的比较
   系统调用|select|poll|epoll
  ---|:--:|:--:|---:
  事件集合|用户通过3个参数分别传入感兴趣的可读、可写及异<br>常等事件，内核通过对这些参数的在线修改来反馈其中<br>的就绪事件。这使得用户每次调用select都要重置这3<br>个参数|统一处理所有事件类型，因此只需要一个事件集参数。<br>用户通过poll.events传入感兴趣的事件，内核通过<br>修改pollfd.revents反馈其中就绪的事件|内核通过一个事件表直接管理用户感兴趣的所有<br>事件。因此每次调用epoll_wait时，无须反复传入用户感兴趣的事件。epoll_wait<br>系统调用的参数events仅用来反馈就绪的事件。
应用程序索引就绪文件<br>描述符的时间复杂度|O(n)|O(n)|O（1）
最大支持文件描述符数|一般有最大值限制|65535|65535
工作模式|LT|LT|支持ET高效模式
内核实现和工作效率|采用轮询方式来检测就绪事件，算法时间复杂度为O(n)|采用轮询方式来检测就绪事件，算法时间复杂度为O(n)|采用回调方式来检测就绪事件，算法时间复杂度为O(1)
